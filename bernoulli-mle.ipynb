{
 "metadata": {
  "name": "",
  "signature": "sha256:720f37b2a4728db40db34db1e8f70456fabf2730b1a02d86531b00e39566676b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#The Intuition behind Maximum Likelihood Estimation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This tutorial is meant as a brief explanation of [Maximum Likelihood estimation](http://en.wikipedia.org/wiki/Maximum_likelihood_estimation) for those who have never seen it before. It covers the basic idea behind MLE, using parameter estimation for the Bernoulli distribution as an example. This is oriented towards readers who have an intuitive idea of probability distributions and have seen basic calculus before, but doesn't assume anything more than that. My hope is that a reader who is not familiar with MLE will be able to understand how the method formalizes some very basic intuition about what data represents, and is geared towards someone who doesn't necessarily have a lot of experience with mathematical formalism besides high school/undergraduate statistics and calculus."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##The Problem: Inferring Parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To start off, we should pin down the problem that we're looking to solve.\n",
      "\n",
      "The problem that maximum likelihood explanation solves is that of *parameter estimation*. Parameter estimation is the very general problem of finding the optimal values of a model's parameters. In other words, we observe some data, and we have a model which we believe represents this data, but we don't know the specific values of the model's parameters. In some cases, the model that we should use isn't obvious - however, for the examples we're going to work on, we'll assume that we have a particular model in mind.\n",
      "\n",
      "In order to get a concrete example of some data which follows a parametric model, let's generate some data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "%matplotlib inline\n",
      "from matplotlib import pyplot as plt\n",
      "data = [random.gauss(0,1) for i in range(1000)]\n",
      "plt.hist(data, bins=10)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD9CAYAAABDaefJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGHdJREFUeJzt3X9Q1Pedx/H3F8FJPVBxPBazS26tQHD9wXJadO5iu1ZR\nm1SCNUeEavYM3tyY6Q9jelGbJoHrKJgm6Wk63mRSTdemkTBNA7SnFs34bWxqglpoTFYD3kGFBTYa\nIEJMCsj3/rCbUOTHirBf+Ph8zHxm1v1+v/t+fxf3xXe/fPa7mmEYAgBQQ5jZDQAAhg+hDgAKIdQB\nQCGEOgAohFAHAIUQ6gCgkAFD/dNPP71twYIFbzudzkqHw+Hdtm1bvohIc3PzlLS0tCOJiYlVy5Yt\nK2ttbZ0c2CY/P39bQkJCdVJS0rmysrJlI70DAIDPaYPNU79y5cqECRMmXOnq6gq/6667fv/0009/\nr7S0NH3q1KmXHn300ad27ty5paWlJbqgoGCr1+t1ZGdnv3zy5Mkv+Xw+69KlS49WVVUlhoWFdYdo\nfwDgljbo6ZcJEyZcERHp6OgYf/Xq1XHR0dEtpaWl6W632yMi4na7PcXFxRkiIiUlJfdmZWUdiIiI\n6LTb7bXx8fHny8vLU0d2FwAAAYOGend3d5jT6ay0WCz+xYsXH5s1a9Z7fr/fYrFY/CIiFovF7/f7\nLSIiDQ0Nt9tstvrAtjabrd7n81lHrn0AQE/hg60QFhbWXVlZ6fzoo48mLV++/LfHjh1b3HO5pmmG\npmn9nsPpa9lA6wMA+mcYhjbQ8qBnv0yaNOmje+65539Onz49z2Kx+JuammJFRBobG6fFxMR8ICJi\ntVp9dXV1cYFt6uvrbVar1ddPY6N+PPnkk6b3oEqfY6FH+qTP0T6CMWCoX7p0aWpgZssnn3zyhSNH\njqSlpKRUpKenl3o8HreIiMfjcWdkZBSLiKSnp5cWFhau6ejoGF9TUzO9uro6ITU1tTyoTgAAN23A\n0y+NjY3T3G63p7u7O6y7uzts3bp1P1+yZMnrKSkpFZmZmUV79+7NsdvttUVFRZkiIg6Hw5uZmVnk\ncDi84eHhXXv27HmIUy0AEDqDTmkckaKaZphR90bpui4ul8vsNgY1FvocCz2K0Odwo8/hpWmaGIOc\nUyfUAWCMCCbUuUwAACiEUAcAhRDqAKAQQh0AFEKoA4BCCHUAUAihDgAKIdQBQCGEOgAohFAHAIUQ\n6gCgEEIdABRCqAOAQgh1AFAIoQ4ACiHUAUAhhDoAKIRQBwCFEOoAoJBwsxsARqOJE6dIW1tLyOtG\nRUXL5cvNIa8LdfDF00AfNE0TETP+j2rCawP94YunAeAWQ6gDgEIIdQBQCKEOAAoh1AFAIYQ6AChk\nwFCvq6uLW7x48bFZs2a9N3v27Hd37979HRGR3NzcXJvNVp+SklKRkpJScejQoa8FtsnPz9+WkJBQ\nnZSUdK6srGzZSO8AAOBzA85Tb2pqim1qaop1Op2V7e3tkfPmzTtdXFycUVRUlBkVFdW2efPmZ3uu\n7/V6HdnZ2S+fPHnySz6fz7p06dKjVVVViWFhYd1/U5R56hjlmKeO0eim56nHxsY2OZ3OShGRyMjI\n9pkzZ571+XxWEenzgUtKSu7Nyso6EBER0Wm322vj4+PPl5eXp97MTgAAghf0OfXa2lp7RUVFysKF\nC98SEXnuuee+nZyc/KecnJy9ra2tk0VEGhoabrfZbPWBbWw2W33glwAwFBMnThFN00I+gLEqqGu/\ntLe3R953332/3LVr13cjIyPbN27c+N9PPPHEf4qIPP744z985JFHntm7d29OX9tqmtbne8nc3NzP\nbrtcLnG5XDfcPNR37for5pwGAcym67roun5D2wwa6p2dnRGrV69+de3atS9lZGQUi4jExMR8EFi+\nYcOGn65cufLXIiJWq9VXV1cXF1hWX19vs1qtvr4et2eoAwCu1/uANy8vb9BtBjz9YhiGlpOTs9fh\ncHg3bdr0X4H7GxsbpwVuv/baa6vmzJlzRkQkPT29tLCwcE1HR8f4mpqa6dXV1QmpqanlQ9gXAMAQ\nDHik/uabb/7zSy+9tHbu3LnvpKSkVIiI7Nix4/sHDhzIqqysdGqaZkyfPr3m+eef/3cREYfD4c3M\nzCxyOBze8PDwrj179jzU3+kXAMDw49K7GNXMnFrIlEaMNlx6FwBuMYQ6ACiEUAcAhRDqAKAQQh0A\nFEKoA4BCCHUAUAihDgAKIdQBQCGEOgAohFAHAIUQ6gCgEEIdABRCqAOAQgh1AFAIoQ4ACiHUAUAh\nhDoAKIRQBwCFEOoAoBBCHQAUQqgDgEIIdQBQCKEOAAoh1AFAIYQ6ACiEUAcAhRDqAKAQQh0AFDJg\nqNfV1cUtXrz42KxZs96bPXv2u7t37/6OiEhzc/OUtLS0I4mJiVXLli0ra21tnRzYJj8/f1tCQkJ1\nUlLSubKysmUjvQMAgM9phmH0u7CpqSm2qakp1ul0Vra3t0fOmzfvdHFxccaLL764furUqZceffTR\np3bu3LmlpaUluqCgYKvX63VkZ2e/fPLkyS/5fD7r0qVLj1ZVVSWGhYV1/01RTTMGqgsEaJomImb8\nXzGvLq8N9EfTNDEMQxtonQGP1GNjY5ucTmeliEhkZGT7zJkzz/p8PmtpaWm62+32iIi43W5PcXFx\nhohISUnJvVlZWQciIiI67XZ7bXx8/Pny8vLU4dohAMDAwoNdsba21l5RUZGyYMGCt/1+v8VisfhF\nRCwWi9/v91tERBoaGm5fuHDhW4FtbDZbvc/ns/b1eLm5uZ/ddrlc4nK5hrgLAKAmXddF1/Ub2iao\nUG9vb49cvXr1q7t27fpuVFRUW89lmqYZmqb1+36xv2U9Qx0AcL3eB7x5eXmDbjPo7JfOzs6I1atX\nv7pu3bqfZ2RkFItcOzpvamqKFRFpbGycFhMT84GIiNVq9dXV1cUFtq2vr7dZrVbfDe8JAGBIBgx1\nwzC0nJycvQ6Hw7tp06b/Ctyfnp5e6vF43CIiHo/HHQj79PT00sLCwjUdHR3ja2pqpldXVyekpqaW\nj+wuAAACBpz98vvf//6uL3/5y2/MnTv3ncBplPz8/G2pqanlmZmZRRcuXLjDbrfXFhUVZU6ePLlV\nRGTHjh3f37dv34Ph4eFdu3bt+u7y5ct/e11RZr8gSMx+AT4XzOyXAUN9pBDqCBahDnzupqc0AgDG\nFkIdABRCqAOAQgh1AFAIoQ4ACiHUAUAhhDoAKIRQBwCFEOoAoBBCHQAUQqgDgEKC/pIM3NomTpwi\nbW0tZrcBYBBc0AtBuRUvrMUFvTDacEEvALjFEOoAoBBCHQAUQqgDgEIIdQBQCKEOAAoh1AFAIYQ6\nACiEUAcAhRDqAKAQQh0AFEKoA4BCCHUAUAihDgAKIdQBQCGDhvqDDz64z2Kx+OfMmXMmcF9ubm6u\nzWarT0lJqUhJSak4dOjQ1wLL8vPztyUkJFQnJSWdKysrWzZSjQMArjfol2QcP358UWRkZPsDDzyw\n/8yZM3NERPLy8p6Miopq27x587M91/V6vY7s7OyXT548+SWfz2ddunTp0aqqqsSwsLDuvynKl2SM\nOXxJRujq8tpAf4blSzIWLVp0PDo6+rrvMevrgUtKSu7Nyso6EBER0Wm322vj4+PPl5eXp95Y2wCA\noRryd5Q+99xz396/f/8D8+fPP/XMM888Mnny5NaGhobbFy5c+FZgHZvNVu/z+ax9bZ+bm/vZbZfL\nJS6Xa6itAICSdF0XXddvaJshhfrGjRv/+4knnvhPEZHHH3/8h4888sgze/fuzelrXU3T+nwv2TPU\nAQSE//VUV2hFRUXL5cvNIa+LgfU+4M3Lyxt0myHNfomJiflA0zRD0zRjw4YNPw2cYrFarb66urq4\nwHr19fU2q9XqG0oN4NbUJdfO5Yd2tLVdd4YVY9SQQr2xsXFa4PZrr722KjAzJj09vbSwsHBNR0fH\n+JqamunV1dUJqamp5cPVLABgYIOefsnKyjrwu9/97iuXLl2aGhcXV5eXl/ekruuuyspKp6ZpxvTp\n02uef/75fxcRcTgc3szMzCKHw+ENDw/v2rNnz0P9nX4BAAy/Qac0jkhRpjSOOUxpVL8ur8nRb1im\nNAIAxg5CHQAUQqgDgEIIdQBQCKEOAAoh1AFAIYQ6ACiEUAcAhRDqAKAQQh0AFEKoA4BCCHUAUAih\nDgAKIdQBQCGEOgAohFAHAIUQ6gCgEEIdABRCqAOAQgh1AFAIoQ4ACiHUAUAhhDoAKIRQBwCFEOoA\noBBCHQAUQqgDgEIIdQBQyKCh/uCDD+6zWCz+OXPmnAnc19zcPCUtLe1IYmJi1bJly8paW1snB5bl\n5+dvS0hIqE5KSjpXVla2bKQaBwBcb9BQX79+/YuHDx9e0fO+goKCrWlpaUeqqqoSlyxZ8npBQcFW\nERGv1+t45ZVX7vd6vY7Dhw+veOihh/Z0d3fzbgAAQmTQwF20aNHx6Ojolp73lZaWprvdbo+IiNvt\n9hQXF2eIiJSUlNyblZV1ICIiotNut9fGx8efLy8vTx2Z1gEAvYUPZSO/32+xWCx+ERGLxeL3+/0W\nEZGGhobbFy5c+FZgPZvNVu/z+ax9PUZubu5nt10ul7hcrqG0AgDK0nVddF2/oW2GFOo9aZpmaJpm\nDLS8r/t7hjoA4Hq9D3jz8vIG3WZI57stFou/qakpVkSksbFxWkxMzAciIlar1VdXVxcXWK++vt5m\ntVp9Q6kBALhxQwr19PT0Uo/H4xYR8Xg87oyMjOLA/YWFhWs6OjrG19TUTK+urk5ITU0tH86GAQAD\nMAxjwLFmzZoD06ZNa4iIiOiw2Wx1+/btW//hhx9OWbJkydGEhISqtLS0spaWlsmB9bdv3/79GTNm\nnL/zzjvPHT58eHlfj3mtLMYSETFEDBMGdUNVF6PfX39O12Vqz6FdWy+0NE0zzKiLodM0TUTM+JlR\nN1R1eU2OfpqmiWEY2kDrMIccABRCqAOAQgh1AFAIoQ4ACiHUAUAhhDoAKIRQBwCFEOoAoBBCHQAU\nQqgDgEIIdQBQCKEOAAoh1AFAIYQ6ACiEUAcAhRDqAKAQQh0AFEKoA4BCCHUAUAihDgAKIdQBQCHh\nZjeAGzdx4hRpa2sxuw0Ao5BmGEboi2qaYUZdVWiaJiKhfv7MqEndUNblNTn6aZomhmFoA63DkToA\nEQn/68FCaEVFRcvly80hr6syQh2AiHSJGe8Q2tpC/4tEdfyhFAAUQqgDgEIIdQBQyE2dU7fb7bUT\nJ068PG7cuKsRERGd5eXlqc3NzVPuv//+V/785z//g91ury0qKsqcPHly63A1DADo300dqWuaZui6\n7qqoqEgpLy9PFREpKCjYmpaWdqSqqipxyZIlrxcUFGwdnlYBAIO56dMvvedMlpaWprvdbo+IiNvt\n9hQXF2fcbA0AQHBu+kh96dKlR+fPn3/qhRde+DcREb/fb7FYLH4REYvF4vf7/ZbhaBQAMLibOqf+\n5ptv/vO0adMaL168+PdpaWlHkpKSzvVcrmmaoWlan5Nfc3NzP7vtcrnE5XLdTCsAoBxd10XX9Rva\nZtguE5CXl/dkZGRk+wsvvPBvuq67YmNjmxobG6ctXrz42Llz55L+piiXCbgpXCaAuirVJQuCF8xl\nAoZ8+uXKlSsT2traokREPv74478rKytbNmfOnDPp6emlHo/HLSLi8XjcGRkZxUOtAQC4MUM+Uq+p\nqZm+atWq10REurq6wr/5zW/+Ytu2bfnNzc1TMjMziy5cuHBHf1MaOVK/ORypU1elumRB8II5Uucq\njWMQoU5dleqSBcEb0dMvAIDRh1AHAIUQ6gCgEEIdABRCqAOAQgh1AFAIoQ4ACiHUAUAhhDoAKIRQ\nBwCFEOoAoBBCHQAUQqgDgEIIdQBQCKEOAAoh1AFAIYQ6ACiEUAcAhRDqAKAQQh0AFEKoA4BCws1u\nAMCtLFw0TQt51aioaLl8uTnkdUOBUL8JEydOkba2FrPbAMawLhExQl61rS30v0hCRTOM0D+hmqYZ\nZtQdbteOMMzYDzPq3kr7St1boe5YzCBN08QwjAF/I3FOHQAUQqgDgEIIdQBQCKEOAAoZkVA/fPjw\niqSkpHMJCQnVO3fu3DISNUJB13WzWwiSbnYDQdDNbiBIutkNBEk3u4Eg6WY3EJSx81of3LCH+tWr\nV8d961vf+snhw4dXeL1ex4EDB7LOnj07c7jrhMLY+UHrZjcQBN3sBoKkm91AkHSzGwiSbnYDQRk7\nr/XBDfs89fLy8tT4+Pjzdru9VkRkzZo1hSUlJffOnDnz7HDXEhE5ceKEnDhxYiQeWk6cOCHPPvts\nn8vGjRs3IjUBhML1H3rKy8sb8aqh+NDTsIe6z+ezxsXF1QX+bbPZ6t9+++0Fw10noKBgt5SWFo7U\nw0tZWdmIPTYAs/T+0FPuX8fICsWHnoY91DVNC2pGvxkfDR4ZZu1H77ojf5Rx8/s61B5D/RwH+hwt\nP9v+DPfPfKT2d7A+R8vzHIrX0Mhn37CHutVq9dXV1cUF/l1XVxdns9nqe64z2CeiAABDM+x/KJ0/\nf/6p6urqhNraWntHR8f4V1555f709PTS4a4DALjesB+ph4eHd/3kJz/51vLly3979erVcTk5OXtH\n6o+kAIBeDMMwbTz99NOPaJrW/eGHH04xs4/+xg9+8IMfzp0790/JycmVX/3qV1+/cOFCnNk99TW+\n973v/SgpKens3Llz/7Rq1apftba2TjK7p75GUVHRvzgcjvfCwsKunj59+h/N7qf3OHTo0Io777zz\nXHx8fHVBQcEWs/vpa6xfv35fTEyMf/bs2WfM7mWgceHChTiXy3XM4XC8N2vWrHd37dr1HbN76j0+\n+eST21JTU99OTk6unDlzpnfr1q35Zvc00Ojq6hrndDorvv71r/96oPVM/aEvX778sN1urxmtoX75\n8uWowO3du3d/Oycn56dm99TXKCsrS7t69WqYYRiyZcuWgi1bthSY3VNf4+zZs0nvv/9+osvlOjba\nQr2rq2vcjBkzztfU1Ng7OjoikpOTK71e70yz++o93njjjUV//OMfU0Z7qDc2NsZWVFQ4DcOQtra2\nyMTExPdH4/P58ccfTzAMQzo7O8MXLFjw1vHjx+8yu6f+xjPPPLM5Ozv7FytXriwdaD3TLhOwefPm\nZ5966qlHzaofjKioqLbA7fb29sipU6deMrOf/qSlpR0JCwvrFhFZsGDB2/X19Taze+pLUlLSucTE\nxCqz++hLz89XREREdAY+X2F2X70tWrToeHR09Ki/iH9sbGyT0+msFBGJjIxsnzlz5tmGhobbze6r\ntwkTJlwREeno6Bh/9erVcVOmTBmV35xRX19vO3jw4N0bNmz4qTEaL71bUlJyr81mq587d+47ZtS/\nEY899tj2O+6444LH43Fv3bq1wOx+BrNv374H77777oNm9zHW9PX5Cp/PZzWzJ1XU1tbaKyoqUhYs\nWPC22b301t3dHeZ0OistFot/8eLFxxwOh9fsnvry8MMP//hHP/rRfwQO3gYyYt98lJaWdqSpqSm2\n9/3bt29/LD8/f1tZWdmywH2D/eYZSf31uWPHju+vXLny19u3b39s+/btjxUUFGx9+OGHf/ziiy+u\nH419ilx7bsePH9+RnZ39cug7vCaYPkejYD9fgRvT3t4eed999/1y165d342MjGw3u5/ewsLCuisr\nK50fffTRpOXLl/9W13WXy+XSze6rp9/85jdfj4mJ+SAlJaVC13XXYOuPWKgfOXIkra/733333dk1\nNTXTk5OT/yRy7W3FvHnzTpeXl6fGxMR8MFL99Ke/PnvLzs5+2cwj4MH6/NnPfvavBw8evPv1119f\nEqqe+hLs8znaBPP5CtyYzs7OiNWrV7+6du3alzIyMorN7mcgkyZN+uiee+75n1OnTs0fbaH+hz/8\n4Z9KS0vTDx48ePenn3562+XLlyc+8MAD+/fv3/9AnxuYffJ/NP+htKqqKiFwe/fu3d9eu3btz83u\nqa9x6NChFQ6H472LFy9ONbuXYIbL5Tp26tSpeWb30XN0dnaGf/GLX/zfmpoa+1/+8pfxo/UPpYZh\nSE1NjX20/6G0u7tbW7du3f5Nmzb92Oxe+hsXL16c2tLSMtkwDLly5coXFi1a9MbRo0eXmN3XQEPX\n9a+M2tkvgTF9+vT/G62hvnr16l/Onj37THJycuU3vvGNV/1+f4zZPfU14uPjq++4444/O53OCqfT\nWbFx48Y9ZvfU1/jVr361ymaz1d12222fWCyWphUrVhwyu6ee4+DBg19LTEx8f8aMGed37Nixzex+\n+hpr1qw5MG3atIbx48f/xWaz1e3bt2+92T31NY4fP36XpmndycnJlYH/l4cOHVphdl89xzvvvDMn\nJSXlj8nJyZVz5sx556mnnvoPs3sabOi6/pXBZr+Y8sXTAICRwTcfAYBCCHUAUAihDgAKIdQBQCGE\nOgAohFAHAIX8P1odjTR9dVfdAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0xa90150c>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, the data is drawn from a Gaussian (Normal) distribution, with mean = 0 and standard deviation = 1. The mean and standard deviation are the parameters.\n",
      "\n",
      "Now, in this example, we saw how the data was generated - we know the model (a Gaussian distribution) and the parameters of that model (the mean and standard deviation). However, in lots of cases, we have a model in mind but don't know the parameters - the method of maximum likelihood gives us one way of inferring the parameter values from data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Method of Maximum Likelihood: Assumptions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, we know that we have a model, some data, and we want to make an inference about the parameter's values from the data. We could have all sorts of interesting models - however, we'll limit ourselves to the specific case of finding the parameters of a probability distribution, a problem known as [density estimation](http://en.wikipedia.org/wiki/Density_estimation). Let's pick some symbols to express the things we're talking about:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parameters:  $\\theta$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data: $D = [d_1...d_n]; d_i \\in \\mathbb{R}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Probability of observing a single datapoint, given the model parameters: $P(d|\\theta)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For our problem, the probability distribution P will have a specific form - in the example above, it was the Gaussian. Now that we've got that out of the way, we want to be able to form and evaluate hypotheses about the parameter values. \n",
      "\n",
      "What makes a good hypothesis in this case? If we have two possible values of the parameters, how can we figure out which one is better using the data? Broadly speaking, we're going to make an assumption here - if we have two hypotheses, we'll say that we prefer the one that best explains the data.\n",
      "\n",
      "Let's see if we can write that idea down more formally. Let's say that we have two possible values of the parameters which we'll call $\\theta_1,  \\theta_2$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we only have one data point, we can compare the likelihood that the datapoint was produced for each possible value of the parameters:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\theta_{best} = arg max_{\\theta_1, \\theta_2} [P(d|\\theta)]$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the formal way of saying the above - that is, that we prefer the the hypothesis which makes the single observed data point most likely. However, at first glance this doesn't seem all that useful - in real life, we always have a number of data points, and we have to choose a hypothesis from among many competing hypotheses. Think about the Gaussian-distributed data in the first example - if we didn't know  the mean, the space of possible hypotheses is tremendous, since the mean's value can be any real number. How can we systematically analyze the space of all possible hypotheses in such a complicated case? The answer leads us to our next section, the introduction of a formalism called the Likelihood function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Evaluating a hypothesis: The Likelihood Function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$L(\\theta, D) = \\Pi_{d \\in D} P(d|\\theta)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\theta_{mle} = arg max[L(\\theta, D)]$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Example: The Bernoulli Distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$P(x|\\mu) = \\mu^{x} (1-\\mu)^{1-x} $"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$L(\\mu, D) = \\Pi_{d \\in D} \\mu^{d} (1-\\mu)^{1-d}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$ln [L(\\mu, D)] = \\sum_{d \\in D} d ln (\\mu) + (1-d) ln (1-\\mu)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\frac{dL}{d\\mu} = \\sum [ \\frac{d}{\\mu} + \\frac{1 - d}{\\mu - 1} ]$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\sum \\frac{d}{\\mu_{ml}} + \\frac{1 - d}{\\mu_{ml}-1} = 0$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\implies \\sum \\frac{d}{\\mu_{ml}} = \\sum \\frac{d-1}{\\mu_{ml}-1} $"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\implies \\mu_{ml} = \\frac{\\sum d}{n}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Another goddamned coin flipping example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##The End: References and Last remarks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}