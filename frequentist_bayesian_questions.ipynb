{
 "metadata": {
  "name": "",
  "signature": "sha256:5dceca0a13b8682e6b7fa59a2c5e9b37eb0f42daf2160bfdc10e5b0b14b5baf8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Frequentist and Bayesian Perspectives in statistical inference"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "How to read this"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This IPython notebook briefly explains some of the differences between frequentist and bayesian viewpoints in statistical inference. In particular, I want to consider some very foundational questions about probabilities, data, and inferring things from data.\n",
      "\n",
      "Each sections contains a basic question about probability and inference; I'll start by clarifying the question, and then present some possible ways that a frequentist and a bayesian might answer it respectively. \n",
      "\n",
      "Specifically, I'll start by explaining each side's viewpoint on just what probability and inference are. In order to see how the inference procedures work in practice, I'll follow with the consideration of a classical problem, parameter estimation for the Gaussian distribution. My goal is to start with an intuitive description of the fundamental assumptions on each side, and then show how those assumptions lead to meaningfully procedures for inference.\n",
      "\n",
      "I originally wrote a version of this for myself in order to better understand the difference between the two schools of thought; while I had an intuitive idea of how each worked, it took me some time to really internalize how the two methods were used in practice. This is intended to do just that; summarize the key ideas of each side and show an example of how a frequentist and a bayesian might solve the same problem respectively.\n",
      "\n",
      "In order to get the most of this, I would recommend that you have a basic understanding of single-variable differentiation (a college calculus course will likely suffice), familiarity with the normal distribution and basic statistics (similarly, a college intro statistics course should give you the needed background), and a working knowledge of Python. I'll be doing my best to include sources where possible, particularly links to primary sources. This topic is incredibly expansive; this guide is aimed at clarifying the basic ideas of each viewpoint, with the understanding that the interested reader can find a more comprehensive explanation both in the provided sources and in the \"Further Reading\" section down the page."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What do probabilities represent?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. P(e) = r\n",
      "\n",
      "2. Probabilities represent the long-run frequencies of an event's occurrence.\n",
      "\n",
      "3. Probabilities represent a subjective measurement of the sureness of a particular outcome."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "How can we construct and evaluate hypotheses based on data?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. What is a hypothesis? What are good and bad hypotheses?\n",
      "2. One frequentist technique of making point estimates is the maximum likelihood method. A good hypothesis does a good job of explaining the observed phenomenon.\n",
      "3. We can quantify our uncertainty about the strength of a hypothesis as a probability distribution."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What do the data points represent?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. What is the interpretation of a set of observations?\n",
      "2. A data point is a finite sample of a very large or infinite population.\n",
      "3. A data point is an event which contributes to our level of sureness about a hypothesis."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "How can we make inferences about the parameters of the Gaussian?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. How does the data enable us to form hypotheses about the average and standard deviation?\n",
      "2. The MLE allows us to find the specific values for the parameters which best explain the sample data, and correspond to the true values of those parameters in as much as the sample is representative.\n",
      "3. We begin by assigning a prior distribution which encodes our beliefs about the parameters, and then we update that distribution based on the observed data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "How can we make these inferences automatically?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. How can we write a program which will automatically produce hypotheses about the data?\n",
      "2. We can derive the MLE for the parameters of the gaussian, and apply the derived formulae to the sample data.\n",
      "3. We can model the prior distribution and update it to obtain the posterior; we can then sample from the posterior."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What are the drawbacks of each method?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Why isn't everyone a frequentist? Why isn't everyone a Bayesian?\n",
      "2. Maximum likelihood is highly dependent on the assumption that the sample is representative, and the estimator itself has very high variance (in particular, MLE for Gaussian parameters is not robust to outliers). \n",
      "3. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The End"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Further Reading"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}